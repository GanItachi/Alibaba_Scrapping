from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from sqlalchemy.orm import Session
from api.database import SessionLocal
from api.models import Categorie
import time
import sys
from pathlib import Path
# Ajouter le r√©pertoire racine au PYTHONPATH
root_dir = Path(__file__).resolve().parent.parent
sys.path.append(str(root_dir))
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# ‚úÖ Configuration de Selenium
def setup_driver():
    """Configure et retourne le driver Chrome."""
    chrome_options = Options()
    chrome_options.add_argument("--headless=new")  # Mode sans interface
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-extensions")
    chrome_options.add_argument("--disable-infobars")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")
    return webdriver.Chrome(options=chrome_options)

# ‚úÖ Scraping des cat√©gories Alibaba
def scrape_alibaba():
    """Scrape les cat√©gories de produits Alibaba et retourne un dictionnaire {nom_cat√©gorie: lien}."""
    driver = setup_driver()
    results = {}

    try:
        print("üîç Acc√®s √† Alibaba...")
        driver.get("https://www.alibaba.com/")
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "industry-row"))
        )

        print("‚úÖ Extraction des cat√©gories en cours...")
        # Extraction avec JavaScript
        categories = driver.execute_script("""
            let data = {};
            document.querySelectorAll('div.industry-row a').forEach(a => {
                let title = a.getAttribute('title');
                let link = a.getAttribute('href');
                if (title && link) data[title] = link;
            });
            return data;
        """)

        results.update(categories)

    except Exception as e:
        print(f"‚ùå Erreur lors du scraping : {e}")
    finally:
        driver.quit()

    print(f"‚úÖ {len(results)} cat√©gories r√©cup√©r√©es.")
    return results

# ‚úÖ Stockage des cat√©gories dans la base PostgreSQL
def store_categories_in_db(categories):
    """Stocke les cat√©gories scrapp√©es dans la base de donn√©es en √©vitant les doublons."""
    db = SessionLocal()
    try:
        for title, link in categories.items():
            # V√©rifier si la cat√©gorie existe d√©j√†
            existing_category = db.query(Categorie).filter(Categorie.link == link).first()
            if not existing_category:
                new_category = Categorie(title=title, link=link)
                db.add(new_category)
                print(f"üÜï Ajout : {title} ({link})")
        
        db.commit()
        print("‚úÖ Toutes les cat√©gories ont √©t√© enregistr√©es avec succ√®s.")
    except Exception as e:
        db.rollback()
        print(f"‚ùå Erreur lors de l'insertion en base : {e}")
    finally:
        db.close()

# ‚úÖ Fonction principale
if __name__ == "__main__":
    scraped_categories = scrape_alibaba()
    store_categories_in_db(scraped_categories)
