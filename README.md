
---

# ğŸš€ Alibaba Scraper API

## ğŸ“Œ Description

**Alibaba Scraper API** est une application basÃ©e sur **FastAPI** permettant de :

* Scraper automatiquement des **catÃ©gories** et **produits** dâ€™Alibaba (via **Selenium**)
* Stocker les donnÃ©es dans **PostgreSQL**
* GÃ©rer les tÃ¢ches asynchrones avec **Celery + Redis**
* Fournir des options de tÃ©lÃ©chargement (JSON, CSV, Excel)
* Surveiller le pipeline avec **Prometheus + Grafana**
* AccÃ©der facilement aux donnÃ©es via un **Tableau de bord**

ğŸ‘‰ Ce projet sâ€™adresse autant aux **dÃ©veloppeurs** (qui veulent contribuer) quâ€™aux **utilisateurs finaux** (qui veulent juste lancer du scraping et tÃ©lÃ©charger des donnÃ©es).

---

## ğŸ› ï¸ Technologies utilisÃ©es

* âš¡ **FastAPI** â€“ API REST
* ğŸ‡ **Celery** â€“ Gestion des tÃ¢ches asynchrones
* ğŸ›‘ **Redis** â€“ Broker pour Celery
* ğŸŒ **Selenium** â€“ Scraping
* ğŸ—„ï¸ **PostgreSQL** â€“ Base de donnÃ©es
* ğŸ“¦ **Docker & Docker Compose** â€“ Conteneurisation
* ğŸ“‰ **Prometheus** â€“ Monitoring des mÃ©triques
* ğŸ“Š **Grafana** â€“ Visualisation des mÃ©triques
* ğŸ–¥ï¸ **PgAdmin** â€“ Gestion de PostgreSQL

---

## âš™ï¸ Installation (DÃ©veloppeurs)

### 1. Cloner le projet

```bash
git clone https://github.com/ton-username/alibaba-scraper.git
cd alibaba-scraper
```

### 2. Lancer avec Docker

```bash
docker-compose up --build
```

### 3. AccÃ©der aux services

* ğŸŒ **API FastAPI** : [http://127.0.0.1:8000](http://127.0.0.1:8000)
* ğŸ“Š **Tableau de Bord API** : [http://127.0.0.1:8000/tb](http://127.0.0.1:8000/tb)
* ğŸ—„ï¸ **PgAdmin** : [http://127.0.0.1:5050](http://127.0.0.1:5050)
* ğŸ“‰ **Prometheus** : [http://127.0.0.1:9090](http://127.0.0.1:9090)
* ğŸ“Š **Grafana** : [http://127.0.0.1:3100](http://127.0.0.1:3100)

---

## ğŸ“‚ Structure du projet

```
â”œâ”€â”€ api
â”‚   â”œâ”€â”€ main.py           # EntrÃ©e FastAPI
â”‚   â”œâ”€â”€ tasks.py          # TÃ¢ches Celery
â”‚   â”œâ”€â”€ models.py         # ModÃ¨les SQLAlchemy
â”‚   â”œâ”€â”€ database.py       # Connexion DB
â”‚   â”œâ”€â”€ scheduler.py      # Scraping automatique
â”‚   â”œâ”€â”€ celery_config.py  # Config Celery
â”‚   â””â”€â”€ ...
â”œâ”€â”€ static                # CSS / JS / Images
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## â³ Automatisation du scraping

* Le scraping est lancÃ© automatiquement toutes les **6 heures** (modifiable dans `scheduler.py`)
* Lancement manuel possible via :

### API (navigateur)

```
http://127.0.0.1:8000/start_scraping
```

### Ligne de commande (`curl`)

```bash
curl -X POST http://127.0.0.1:8000/start_scraping
```

### VÃ©rifier lâ€™Ã©tat dâ€™une tÃ¢che

```bash
curl http://127.0.0.1:8000/status/<TASK_ID>
```

---

## ğŸ“Š Monitoring (DÃ©veloppeurs & Admins)

* **Prometheus** collecte automatiquement les mÃ©triques (nombre de tÃ¢ches, temps dâ€™exÃ©cution, erreurs, files dâ€™attente).
* **Grafana** propose un dashboard visuel personnalisable.

ğŸ‘‰ Exemples de mÃ©triques :

* `celery_tasks_total` â†’ Nombre total de tÃ¢ches exÃ©cutÃ©es
* `celery_task_duration_seconds` â†’ Temps moyen dâ€™exÃ©cution
* `celery_tasks_queued` â†’ Nombre de tÃ¢ches en attente

---

## ğŸ“– Guide Utilisateur (Simple)

### 1. AccÃ©der au Tableau de Bord

ğŸ‘‰ [http://127.0.0.1:8000/tb](http://127.0.0.1:8000/tb)

Depuis cette interface, vous pouvez :

* Lancer un scraping
* Voir les rÃ©sultats
* TÃ©lÃ©charger les donnÃ©es

---

### 2. TÃ©lÃ©charger les donnÃ©es

#### ğŸ“‚ CatÃ©gories

* [JSON](http://127.0.0.1:8000/download/categories/json)
* [CSV](http://127.0.0.1:8000/download/categories/csv)
* [Excel](http://127.0.0.1:8000/download/categories/excel)

#### ğŸ“¦ Produits

* [JSON](http://127.0.0.1:8000/download/produits/json)
* [CSV](http://127.0.0.1:8000/download/produits/csv)
* [Excel](http://127.0.0.1:8000/download/produits/excel)

---

### 3. Exemple dâ€™utilisation rapide

1. Ouvrir le **Tableau de bord** : [http://127.0.0.1:8000/tb](http://127.0.0.1:8000/tb)
2. Cliquer sur **Lancer un scraping**
3. Attendre que les donnÃ©es soient disponibles
4. TÃ©lÃ©charger en **CSV** pour ouvrir dans Excel

---

## ğŸ”— Liens utiles

* ğŸ“Š Tableau de Bord : [http://127.0.0.1:8000/tb](http://127.0.0.1:8000/tb)
* ğŸ—„ï¸ PgAdmin : [http://127.0.0.1:5050](http://127.0.0.1:5050)
* ğŸ“‰ Prometheus : [http://127.0.0.1:9090](http://127.0.0.1:9090)
* ğŸ“Š Grafana : [http://127.0.0.1:3100](http://127.0.0.1:3100)

---

## ğŸ“œ Licence

Projet sous licence **MIT**.

---
